<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[俞龙-Data Player]]></title>
  <link href="http://fieryfish.github.io/atom.xml" rel="self"/>
  <link href="http://fieryfish.github.io/"/>
  <updated>2016-02-18T23:26:01+08:00</updated>
  <id>http://fieryfish.github.io/</id>
  <author>
    <name><![CDATA[YuLong]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[关于库存KPI]]></title>
    <link href="http://fieryfish.github.io/blog/2015/05/11/stock-kpi/"/>
    <updated>2015-05-11T22:55:34+08:00</updated>
    <id>http://fieryfish.github.io/blog/2015/05/11/stock-kpi</id>
    <content type="html"><![CDATA[<p>本文主要会聊一些关于库存管理(Inventory Management)的KPI,主要参考了<a href="http://book.douban.com/subject/12565786/">Inventory Management Explained</a>.</p>

<h3 id="section">周转</h3>

<p>周转有很多定义,其中我们最常用的应该是这一个样子:</p>

<p>sku的周转=sku的销量/sku的库存</p>

<p>从公式上我们可以看出来,它所反映的是sku的库存投入与销售量的比例。 
这可能是最常用的反应库存指标的KPI,在Inventory Management Explained的作者看来,
这个KPI虽然很有用, 但可能是最为误用或者滥用的指标。 本质上,
这个KPI反应的仅仅是库存周转的速率,仅此而已,
并不是说高的周转就一定比低的周转好，不过很多误用的地方就在于此，
很多时候企业会以提高周转为主要目标。如果这样是我们所追求的，
那么采购的时候,直接将采购量降为一半、而采购次数变成2倍。
这一‘黄金准则’会使得我们的库存直接保持在原来的一半,
周转优化了整整两倍啊!可是,如果我们采购的成本很高,在财务上,我们这多出来一倍的采购成本是会导致亏钱的。
所以,再次重申,高的周转只意味着你的sku运转的更快了。
另外,<a href="http://www.quora.com/What-metrics-are-most-important-for-Inventory-Management-Why">Quora</a>里面还有一个很有意思的讨论,它把成本维度的周转和毛利率
(Gross Margin or Gross Profit Percent ,GM%) 放在一起讨论。</p>

<p>GM%=<script type="math/tex">\frac{Sales−Cost}{Sales} =1−\frac{Cost}{Sales}</script></p>

<p>如果周转考虑的不是销量角度的,而是成本角度的,那么公式如下:</p>

<p>InventoryTurns = <script type="math/tex">\frac{Cost}{AverageInventoryValue}</script></p>

<p>通过上面两个公式,我们可以看到sku的周转可以转换成:</p>

<script type="math/tex; mode=display">GM\% = 1 − \frac{InventoryTurns∗AverageInventoryValue}{Sales}</script>

<script type="math/tex; mode=display">InventoryTurns = \frac{Sales(1−GM\%)}{AverageInventoryValue}</script>

<p>这里有个很有意思的联系:毛利率和周转是密切相关的,也就说,如果你知道了一个理想的毛利率,那么你也就可以得到一个理想的周转了。
（我不对此结论负责哈）</p>

<h3 id="gross-margin-return-on-inventory-investmentgmroii">Gross Margin Return on Inventory Investment(GMROII)</h3>

<p>Inventory Management Explained书中,作者给出了一个很俏皮的KPI–-GMROII. 
它描述了你投入到库存的钱与商品的利润(毛利)的比率。 
它反映了你每投入到库存的钱,如采购一定金额的商品,与这些库存内的商品获得的利润的比率。 
这个指标很关键,因为它是直接反应你在库存是否很良好的转化为真金白银。 
一个简单的例子(只计算毛利):如果你采购一个东东花了3块, 售价是10块,如果一年你卖了500件,这时总利润是7*500=3500. 
如果这时平均库存数量维持在100件,那么投入到库存的钱是3*100=300块。
GMROII就是3500/300=11.67。 
换句话说:你有300块钱,把他们都采购这件东东,并且一年的平均库存水平维持在100件,
然后一年你赚了3500块钱,回报率是11.67。 
当然我们也可以通过净利润(net profit)计算,这样就可以看到哪些商品是最赚钱的,投资回报率最大的。
这样的KPI可以帮助我们做些什么呢? 
或许我们可以先排序一下sku,看看哪些sku特别赚钱、投资回报率很高,那些投资回报率很低。
我们去分析看看有什么我们可以改进的地方去提升低回报率的sku,比如:提高售价。 
有时候,某个sku的周转很高,看起来很赚钱,但是由于库存过多,
仓储成本过高,当你计算GMROII时可能不那么理想,并没有那么赚钱。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[库存管理之安全库存(2) --Inventory Management--safety stock]]></title>
    <link href="http://fieryfish.github.io/blog/2015/05/10/ss2/"/>
    <updated>2015-05-10T20:51:35+08:00</updated>
    <id>http://fieryfish.github.io/blog/2015/05/10/ss2</id>
    <content type="html"><![CDATA[<p>上文结尾处我们给出了安全库存的意义。其本质就是由于各个因素(如销量)的不确定性，使得我们要寻找一个缓冲，
可以容忍一定的变化范围，保证我们的库存没有断货的问题。这里有个很重要的观点：我们不怕任何程度的变量，
因为通过数学，尤其是统计的方法，我们可以量化出来这些变动，但前提是要找到这些变化。
在一些安全库存的公式中(如<a href="http://www.inventorymanagementreview.org/2005/06/safety_stock.html">安全库存计算公式</a>)，
会考虑销量预测的不确定性和vlt(vendor lead time–供应商送货时长)的不确定性，然而，
实际情况你可能还要量化如供应商能否有货\送货等等的不确定性，很难有一个公式能涵盖所有这些变化。
至于安全库存计算公式，资料很多，就不深入了。大家可以参考<a href="http://en.wikipedia.org/wiki/Safety_stock">wiki</a>，
主要思路就是假设这些变量（销量、vlt）服从正态分布，然后通过正态分布的z-value（库存管理大都称其为称作’服务水平’），
去找到你想要的一个值（如95%），去计算相应的安全库存。</p>

<p>这里我想针对两个点去继续讨论下。一、当我们的服务水平设置为95%的时候，实际缺货的概率大概是怎么样子的？
二、库存的现货率和周转这两个主要的kpi的关系。
一、当我们设置了95%的服务水平的安全库存的时候，我觉得其意义就是说这个vlt时间段内，有5%的可能性，
这个sku的订单不能满足的，仅此而已。假设，这个sku的订购周期是4周，vlt是1周，那么计算这个sku缺货的概率应该是
<!--$$-->
<!--\frac{1}{4}*{5%}=1.25%-->
<!--$$-->
<script type="math/tex">\frac{1}{4} * 5\% = 1.25\%</script>。
这里可以看出，当你的订购周期越长，那么现货率应该是越高的，然而，订购周期越长，也就意味着你要一次订购更多数量的商品。
同时也就意味着，你的周转会变慢，库存的持有成本会增加。
这里相信大家也可以看出来，现货这周转两个是存在制约关系的，我们在采购时候的，当以’少量多次’的形式采购，现货可能会下降，但是周转会变短。
而’多量少次’的形式则反之。与此同时，如果从成本的角度考虑的话，’少量多次’会增加订购成本，
而减少仓储持有成本，
‘多量少次’的则反之。那这种制约关系怎么去搞定呢？答案就是最优化(optimization)。
库存管理很多模型都会基于最优化去求解,
这里就看你的目标函数了，比如在计算补货量的时候，如果你基于成本最优，那么可以得到很经典的EOQ模型。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[库存管理之安全库存(1) --Inventory Management--safety stock]]></title>
    <link href="http://fieryfish.github.io/blog/2015/05/04/ss1/"/>
    <updated>2015-05-04T22:55:08+08:00</updated>
    <id>http://fieryfish.github.io/blog/2015/05/04/ss1</id>
    <content type="html"><![CDATA[<p>来了京东快半年了，重新开始工作感觉还是蛮不错的，回到熟悉的国家，与有着不错背景的同事们一起做事。
不过工作了就要有所取舍，比如我一开始想的是我这辈子肯定要一直奉献与机器学习了，结果，我开始开始做起了库存管理方面的算法。
这些日子做库存管理感觉还蛮有意思的，之后的几篇blog我会介绍一些我对于库存管理一些概念的理解，
它们不一定是’正确’答案，不过却是我对于库存的一些认识。</p>

<p>说到库存管理，我觉得一句话足以描述：在合适的时间，以合适的形式(如持有、退货、补货等)，
对于sku（Stock Keeping Unit，简单理解为一件货品）进行操作，使得库存保持在合适的水平。
这句话随着我做事情的深入，便越来越觉得很精辟。
那么开始这段旅程吧，我们可以先来聊聊一个我觉得很意思的一个话题就是：安全库存(Safety Stock)。
相信有过库存管理经验的人一定对于这个概念不陌生，那么什么是安全库存呢？</p>

<p><img class="left" src="http://fieryfish.github.io/images/ss.jpg" width="400" height="400" title="image" alt="safety stock" /></p>

<p><a href="http://en.wikipedia.org/wiki/Safety_stock">安全库存</a>顾名思义，就是防止断货的一种提前进行补货的策略。
试想，假设我们知道供应商送货需要10天，正常情况下，我们采取的策略是需要提前十天进行采购，
这样可以保证在可用库存为0的时候，我们新的订单就会到货了，这样就不会缺货拉。
然而，我怎么知道这十天会卖多少呢？那就做一些预测喽，然而，再准确的预测也不可能给出一个’正确的’答案。
理想情况下，销量预测和真实销量的差值(残差)会服从N(0,<script type="math/tex">\sigma</script>)的正态分布(Normal distribution)。
在这里插一句，关于<a href="http://en.wikipedia.org/wiki/Normal_distribution">Normal distribution</a>这个钟形曲线，
在库存管理里面无处不在，由于它太’Normal’了，并且有着非常好的性质，
所以我们会有很多假设都是基于这个分布，后面我还会再次对于他进行讨论。
再回到刚才的话题，当我们根据销量预测的结果进行补货的时候，会有一半的概率由于销量预测的偏差导致缺货。
具体来说，如果销量预测对未来一段时间预测是20件/天，
那么当我们设置20*10 = 200件为我们的补货点的时候，如果真实销量是180+或190+件还好，如果真实销量在第8天就到达了200件，那么你就会有至少1天的断货发生。</p>

<p>那么很自然，我们就会想去进行提前补货以防止断货的发生。不过提前多久是合适的？1天,2天还是1周？
这个就是引入安全库存的意义所在。
OK，那关于安全库存的本质，我觉得<a href="http://book.douban.com/subject/12565786/">Inventory Management Explained</a>这本书的观点描述的非常好。
‘safety stock can be used to compensate for supply variablity. More specifically,
we use it to compensate for the amount of demand variablity that may occur during the lead-time period.’
那在下一个blog我会详细阐述这个点。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Machine Learning与数学]]></title>
    <link href="http://fieryfish.github.io/blog/2014/10/20/nn/"/>
    <updated>2014-10-20T08:35:00+08:00</updated>
    <id>http://fieryfish.github.io/blog/2014/10/20/nn</id>
    <content type="html"><![CDATA[<p>如果再给我一次机会(鄙人本科修数学)，我一定会学好一下三门课的。1 线代 2 最优化 3 概率统计
Why？</p>

<p>先说线代，如果说什么是最普遍的表现数据的话，那么大概也就是矩阵了，玩转线代也就是玩转矩阵，就这么简单。
现在满世界都在聊SVD，而一个最直接的例子就是PCA，这里我先介绍一篇<a href="http://blog.codinglabs.org/articles/pca-tutorial.html">blog</a>，写的非常好的。可以看出来，数据降维的关键就是如何寻找新的坐标系去表示数据，也就是同样的数据，如何用更加少的维度去表示更加多的信息。
在寻找新的坐标系时，我们会用到协方差矩阵的对角化，eigenvector,eigenvalue等知识。在实施矩阵坐标变换，我们又会用到投影（projection）等知识。
似乎不会线代，就算知道了PCA整体流程，心里也总是隐隐不安。如果英文还不错，那么<a href="http://book.douban.com/subject/3582335/">Introduction to Linear Algebra</a>配合Gilbert Strang 老师的公开课一定是你的不二选择。
我相信就算大家以前学过这门课，也会再回头温习这们课的。</p>

<p>再说最优化，给我体会最深的是，最优化和神经元网络简直就是孪生兄弟，相信大家都有在SVM的对偶，kkt，拉格朗日搞来搞去的经历。
也会有思考梯度下降、牛顿法的过程。简单想想，从perceptron,MLP到SVM，都伴随着求解最小化损失函数的过程，相信这就是最优化的源头。我也一直怎么弄明白最优化，最近打算抱着<a href="http://book.douban.com/subject/1888111/">Convex Optimization</a>好好啃啃，再看看Stephen Boyd老师的公开课。</p>

<p>最后就是概率统计。很多时候统计学家就是在搞机器学习，很难讲就是哪个属于统计，哪个属于机器学习。不过给我做直观的一个区别就是，统计经常是对已有的数据进行分析，比如各个统计量，一阶、二阶矩等都是有其意义的，可以用来解释数据。而像置信区间，假设检验什么的也都是用“科学的”方法表现数据的意义。而机器学习更多是通过已有的数据训练，再应用到未知数据。当然，好消息就是像基于概率统计的贝叶斯分类器，我们可以通过它知道分类时，测试数据分到各个类别的概率是多少，这样的概率也给了我们去解释为什么的依据。</p>

<p>说了半天，其实我想说的时，这三门课在我看来是要伴随着对机器学习探索而不断重温的科目，各个算法都是基于前人不断迭代的过程，而数学就是这些的基石。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RandomForest(随机森林)]]></title>
    <link href="http://fieryfish.github.io/blog/2014/09/01/randomforest/"/>
    <updated>2014-09-01T22:57:00+08:00</updated>
    <id>http://fieryfish.github.io/blog/2014/09/01/randomforest</id>
    <content type="html"><![CDATA[<p>RandomForest在我印象里，是一个碉堡了的算法，因为用起来很简单，几乎不需要怎么调试就直接得到了很好地效果。
所以这也是为什么在Kaggle的Titanic分类竞赛专门拿RandomForest<a href="http://www.kaggle.com/c/titanic-gettingStarted/details/getting-started-with-random-forests">举例</a>.
在学习RandomForest之前，请保证大家已经基本掌握了Decision Tree。<a href="http://www.quora.com/How-do-random-forests-work-in-laymans-terms">这里</a>有个很好的对于RandomForest的解释。</p>

<p>它的主要思想是将Decision Tree 聚合(ensemble)。根据<a href="http://en.wikipedia.org/wiki/Random_forest">wiki</a>,它的实现主要
通过了bagging和Random subspace method两个方法。为什么要用这两个方法呢? Randomness!
前者是针对训练数据的随机选择，比如1000个实例中随机选择800个去生成树。
它的强悍之处在我看来是因为wiki里的这句话 “Increasing the number of trees tends to decrease the variance of the model,
without increasing the bias.” Decision Tree的问题之一就是容易overfitting,显然bagging很好的解决了这个问题（更多关于overfitting请参考<a href="http://bboxers.com/blog/2014/06/29/curse-learning-curve/">维数灾难到学习曲线</a>)。
后者是针对feature去进行选择，比如从100个
features里面去选择50个,这使得每一个子树都不完全相同。之后再根据正常的Decision Trees算法去生成树，这里有个参数（free parameter）需要用户选择，
就是生成多少个trees，一般来讲，当然是越多越好了，最后根据各个trees的结果去投票(vote)，算出最终的结果。
但是tree多了以后运算会超级慢，这是个不得不要考虑进去的问题，准确+慢 vs 不准确+快？
这时候，Out-of-bag error就是判定生成多大树的标准之一了，<a href="http://www.quora.com/What-is-the-out-of-bag-error-in-Random-Forests">quora</a>有个很好的解释，
大概就是说，在我们bagging的时候，从1000个实例选了800个，那么剩下的那200就组成了out-of-bag examples，
我们可以把这200个实例组成测试的trees，这样通过测试trees就可以大概知道RandomForest的精确度。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[BIC(bayesian information criterion)+likelihood function]]></title>
    <link href="http://fieryfish.github.io/blog/2014/08/18/bic/"/>
    <updated>2014-08-18T23:14:00+08:00</updated>
    <id>http://fieryfish.github.io/blog/2014/08/18/bic</id>
    <content type="html"><![CDATA[<p>首先BIC是干什么的？用于比较在给定的数据下，比较不同模型的准则(criterion)。
怎么比较呢？他会关注两件事情，一更好的拟合结果，二更少的参数。一很好理解，二这是要求
一个相对更简单的模型去防止overfit这种事情。在想不起来的，请看这幅<a href="http://zoonek2.free.fr/UNIX/48_R/g883.png">图</a>。
既然是比较模型，那它也属于model selection的范畴了。
在<a href="http://en.wikipedia.org/wiki/Bayesian_information_criterion">wiki</a>上写了好多感觉还蛮啰嗦的，
开始看了几遍也不怎么知道啥意思，其实主要的公式就是:(实例instance很多的情况下)</p>

<script type="math/tex; mode=display">BIC = -2\cdot ln \hat{L}+k\cdot ln(n)</script>

<p>$\hat{L}$是已经完成了像MLE这种参数估计以后，得到的最优参数的似然函数(Likelihood function)。k是参数的个数，n是实例的个数。
一例胜千言，请大家直接翻到这个很棒的<a href="http://hea-www.cfa.harvard.edu/astrostat/Stat310_0910/dr_20100323_mle.pdf">ppt</a>，29页
有一个简单的例子，相信看完这个例子的人基本也就明白是怎么回事了。</p>

<p>这里有个很重要的叫做Likelihood function(似然函数)的概念，大家在Bayes rule里面应该也有看到过，然后在MLE(极大似然估计)里也有所耳闻。那么究竟它是怎么一回事呢？看个<a href="http://en.wikipedia.org/wiki/Likelihood_function">wiki</a>的例子，非常形象~
在硬币游戏里，H代表head，正常来讲，投掷时候得到head的概率为<script type="math/tex">P_{H}=0.5</script>，那么投掷两次都是head的概率是：
<script type="math/tex">P(HH | P_{H}=0.5) = 0.25</script>。如果用likelihood function去描述它，那么就是: <script type="math/tex">L(P_{H}=0.5 | HH)=P(HH | P_{H}=0.5) = 0.25</script>,
它的含义并不是说给出了观察序列HH，我们得到概率<script type="math/tex">P_{H}=0.5</script>的概率是0.25。
相应地：<script type="math/tex">L(P_{H}=1 | HH)=P(HH | P_{H}=1) = 1</script>,它的含义也并不是说给出了观察序列HH，我们得到概率<script type="math/tex">P_{H}=1</script>的概率是1,
likelihood function不是概率密度（probability density function），下面的图便是我们该问题里<script type="math/tex">P_{H}</script>的分布，可以看出
在观察序列都是HH的时候，我们更愿意相信<script type="math/tex">P_{H}=1</script>，这便完成了一次MLE的过程，在估计参数<script type="math/tex">P_{H}</script>的时候，我们更愿意相信
这个参数的取值是1。</p>

<p><img class="left" src="http://fieryfish.github.io/images/LikelihoodFunctionAfterHH.png" width="600" height="600" title="image" alt="The likelihood function for estimating the probability of a coin landing heads-up without prior knowledge after observing HH" /></p>

<p>另一方面，后验概率(Posterior probability)相对于likelihood function是一个逆过程。
如果是后验概率，这个问题就是<script type="math/tex">P(P_{H} | HH)</script>，其实没什么特别的，知道这个概念就好了，
看到Bayes Rule:</p>

<script type="math/tex; mode=display">P(A|B)=\frac{P(B|A)P(A)}{P(B)}</script>

<p>大家也就知道,后验概率是<script type="math/tex">P(A|B)</script>，似然函数是<script type="math/tex">P(B|A)</script>
,先验概率是<script type="math/tex">P(A)</script>.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[高斯图模型 Gaussian graphical model]]></title>
    <link href="http://fieryfish.github.io/blog/2014/07/17/ggm/"/>
    <updated>2014-07-17T10:18:00+08:00</updated>
    <id>http://fieryfish.github.io/blog/2014/07/17/ggm</id>
    <content type="html"><![CDATA[<p>如果说以前的一些文章还有加入自己的思考的话，那这篇可能是最客观的表述。其实
Gaussian graphical model(GGM)资料还真的蛮少的，我本来也想找找书籍去学习下，结果到最后还是
要去看论文。当然，论文的力量就是可以把一个知识讲到令人发指的长，这篇blog主要是梳理GGM的主要脉络，
有兴趣的同学请直接参考相关论文文献。(Yuan and Lin, 2007 ; Friedman et al. 2008)</p>

<p>首先，什么是Gaussian graphical model？它围绕Gaussian分布的变量去研究各个变量的联系。具体来说就是
要研究Multivariate Normal Distribution.（插一句，这里Normal就是Gaussian，同义词，指正态分布，一般
我们会把很多变量假设为正态分布的，比较典型的就是回归问题里error项拉,其原因就是中心极限定理central limit theorem。）
Multivariate Normal Distribution的核心，是inverse covariance matrix(ICM)，也叫concentraion matrix, precision matrix.
ICM在Multivariate Normal Distribution的密度函数里面，他决定了Gaussian graphical model长什么样子哦。
好了，晕了的同学不好意思，必须要自己wiki一下Multivariate Normal Distribution，
尤其是一个重要的性质：设</p>

<p>covariance matrix: <script type="math/tex">\Sigma</script> ,</p>

<p>inverse covariance matrix:C = $(\Sigma)^{-1} $</p>

<p>$C=(c_{ij})$</p>

<p>如果<script type="math/tex">c_{ij}=0</script>，那么变量i和变量j是独立的。也就是说，高斯图里，两个变量是没有联系的。
学过图论的都知道，图就是node和edge组成的，如果$c_{ij}=0$，则那两个nodes没有edge。
简单屡一下，高斯图模型重点是确定ICM长成什么样子，因为里面的元素为0代表相应的两个变量独立，也就确立了图的样子。
下面我们来聊一聊另一个我们追求的，就是’稀疏’（sparse）。什么意思呢？在图里，不是每一个连接（Edge）都是我们想要的，
换句话说，有时候nodes之间的edge有可能是噪音，应该被去除的，
而又有时候，你只想看哪些nodes之间的连接是显著相关的（significant）。所以这里有2个问题：其一，去除更多
不是很相关的连接，也就是让ICM里面有更多的0，即ICM更加sparse。方法？Lasso regularization。
其二，这是一个trade-off，
如果你想要保留更多的edges，lasso的惩罚项相应的就要小一点,保留的信息也就更多，
反之，你增大lasso的惩罚项，edges就少了，图也就更sparse了一些。</p>

<p>基于上述讨论，我直接给出我们要求解的表达式，具体过程请参考：(Yuan and Lin, 2007)</p>

<p>最大化：$log det (C) − tr(SC) − ρ||C||_{1}$</p>

<p>S is empirical covariance matrix.</p>

<p>解决上述最优化方程有很多方法，像Interior point methods等等，我在我的毕业设计采用了<a href="http://statweb.stanford.edu/~tibs/glasso/">glsso</a>(Friedman et al. 2008)。
它的优点就是快！他采用了block coordinate descent算法去求解上式，这个算法感觉就是奔着快去的。在这个<a href="https://www.cs.cmu.edu/~ggordon/10725-F12/schedule.html">链接</a>里面的
Lecture 25有它的详细介绍，如果论文看不明白可以参考这个教程，其实我现在也在慢慢啃这个知识点，感觉还蛮难的，最优化没学好。。呜呜。。</p>

<p>Anyway,我的毕业设计是关于犬类疾病研究的，最后自己画了一匹藏獒和相应的gaussian graphical model.<a href="http://smileclinic.alwaysdata.net/jackmsc/ggm_dog_network/">Link</a>.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[概率模型probabilistic Model(2) logistic回归]]></title>
    <link href="http://fieryfish.github.io/blog/2014/07/11/logister/"/>
    <updated>2014-07-11T00:18:00+08:00</updated>
    <id>http://fieryfish.github.io/blog/2014/07/11/logister</id>
    <content type="html"><![CDATA[<p>故事是这样的，在概率模型世界，我们要面对的问题就是这样的一个公式：
<script type="math/tex">p(y|\bar{x})</script>,
其中，y是类别(class), $\bar{x}$是输入数据(input data)。
在<a href="http://bboxers.com/blog/2014/06/16/probabilistic-models/">Naive Bayes</a>里面我们已经看到了如何用Bayes公式搞定这个问题。
这次，我们可以用个更直观的方式，怎么搞？
这样？
<script type="math/tex">p(y|\bar{x})=w_{0}+\Sigma(w_{i} \cdot x_{i})</script>,
左边很熟悉（probabilistic model），右边也很熟悉(linear model)，但是，放在一起总是怪怪的。
计算机界有个名言，”Any problem in computer science can 
be solved by adding a layer of indirection”
这次，我们的’layer’就是logistic function。
没听过的同学请先看<a href="http://en.wikipedia.org/wiki/Logistic_function">wiki</a>的解释。
记住公式、记住图的样子，别问为啥。好了，再记住一个它的性质，1-$\theta(x) = \theta(-x)(\theta$表示logistic function)。对比图像看看，怎么样？很直观的一个性质吧。
logistic function就是把右边那个linear model的范围(无穷)缩小到probabilistic model的范围([0,1])了，从而可以让我们用概率的方法搞定它。</p>

<p>既然回归到了概率问题，那就用概率的方式解决。考虑一个普遍的binary classification问题：</p>

<p><img class="left" src="http://fieryfish.github.io/images/binary.png" width="400" height="400" title="image" alt="Binary" /></p>

<p>它同样是<a href="http://en.wikipedia.org/wiki/Bernoulli_distribution">bernoulli distribution</a>。</p>

<p>引入logistic function, 将<script type="math/tex">w_{0}+\Sigma(w_{i} \cdot x_{i})</script>带入到logistic function得到：
<script type="math/tex">\theta(\bar{w}\cdot \bar{x})= \theta(w_{0}+\Sigma(w_{i} \cdot x_{i}))=\frac{1}{1+exp(-(w_{0}+\Sigma(w_{i} \cdot x_{i})))}</script></p>

<p>把它带入上面的方程，得到了:
<script type="math/tex">P(y=+1|\bar{w}\cdot \bar{x})= \frac{1}{1+exp(-(w_{0}+\Sigma(w_{i} \cdot x_{i})))}</script></p>

<p>和
<script type="math/tex">P(y=-1|\bar{w}\cdot \bar{x})=1-\frac{1}{1+exp(-(w_{0}+\Sigma(w_{i} \cdot x_{i})))}</script></p>

<p>然后：
<script type="math/tex">\frac{P(y=+1|\bar{w}\cdot \bar{x})}{P(y=-1|\bar{w}\cdot \bar{x})}= exp(w_{0}+\bar{w}\cdot \bar{x})</script>     (if &gt; 1 , 正例)</p>

<p>两边取对数：
<script type="math/tex">ln\frac{P(y=+1|\bar{w}\cdot \bar{x})}{P(y=-1|\bar{w}\cdot \bar{x})}=w_{0}+\bar{w}\cdot \bar{x}</script></p>

<p>很神奇吧？线性分类器出现了！它的decision boundary就是<script type="math/tex">w_{0}+\bar{w}\cdot \bar{x}</script>, 这种神奇当然要归功于logistic function和它的性质喽！</p>

<p>然后呢，就是训练喽。这里用到的就是概率里面常用到的Maximum likelihood方法。一些推导我直接copy了，请注意
最后的那个就是目标函数。</p>

<p><img class="left" src="http://fieryfish.github.io/images/logis.png" width="600" height="400" title="image" alt="推导" /></p>

<p>问题又被转化为了最优化问题，它是convex的，有最优解，用Gradient Descent就完事了~这里不是课本，就是说这个思路拉。
再补一句，logistic regression会有过拟合问题，需要regularization。
经典方式又出现了: argmin(目标函数+regularization)</p>

<p>logistic regression在我看来是一个有很多标签的分类器。1 人们经常用它作为discriminative model的代表，
跟generative model的代表naive Bayes去比较(<a href="http://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf">比如这篇</a>)。
discriminative model &amp; generative model请大家好好注意一下，这个
区别存在于很多其他地方哦。
(1)generative model是基于p(x,y), discriminative model是基于p(y|x),这样看来discriminative model更加直接，
对于直接的分类问题，准确性相对更高，而且p(x,y)会储存更多值
(2)generative model和discriminative可以互相转化，p(y|x)*p(x)就是p(x,y)。具体问题具体分析，有时候你可能要构建(x,y)而不是(x|y)。
2 它的名字虽然包含regression，但是它做的事情是classification。
3 它是个线性分类器。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[维数灾难到学习曲线(learning curve)]]></title>
    <link href="http://fieryfish.github.io/blog/2014/06/29/curse-learning-curve/"/>
    <updated>2014-06-29T15:47:00+08:00</updated>
    <id>http://fieryfish.github.io/blog/2014/06/29/curse-learning-curve</id>
    <content type="html"><![CDATA[<p><a href="http://bboxers.com/blog/2014/06/29/curse-dim/">上一篇</a>简单聊了聊维数灾难，
这节就10只小猫小狗的例子稍微延伸一下，假设现在给你100只猫猫狗狗，3维已经不能满足线性可分了，这时候
可能直到10维我们才能找到一个超平面（hyperplane）去分离这100个小猫\小狗。但这时候，会引出这样一个问题，过拟合(over-fitting)。
也就是说，这时候尽管10维feature分离100个实例效果很棒，但是对于其他未知的小猫小狗(比如第101,102..个)，它的效果可能并不好！
也就是说，训练数据(training data)的分类效果好并不等同于分类器在测试/未知数据(testing data)的效果好！
我们所追求的应该是更少的泛化误差（generalization error）。</p>

<p>泛化的反面，就是<strong>记录</strong>（memorize）。10维的超平面在这里更像是<strong>记录</strong>我这100个动物是小猫或是小狗，
而不是<strong>学习</strong>(learning)。举个不恰当的例子：
还是之前的小猫\小狗，3维数据可以很好区分10个instances，假设到第11个小猫/小狗，3个feature可能不够用了，那么就增加到4个！
然而这时你这第11个小猫小狗如果是noisy的，即误分类的，就也被‘记录’了下来，而每次发生feature不够用的情况，咱就增加一个feature，
最后就相当于你用了10个feature记录下了100个小动物是小猫还是小狗而已，即使这里面有误分类的，也给无情的记录下来了。
这种记录，对于其他待分类数据，是无用的。
这也就是为什么Decision Tree要选择‘最短路径’，Concept Learning要选择合取式(Conjunctive normal form)而不是析取。
<!--这就是为什么我们有了一系列像cross-validation的方法。--></p>

<p><img class="left" src="http://fieryfish.github.io/images/learning_overfitting.png" width="400" height="400" title="image" alt="Using too many features results in overfitting" /></p>

<p>(这里还要先请大家请自行google 一下cross-validation和bias/variance trade-off，因为后面的内容都是基于cross-validation的，
bias/variance的概念也是要涉及到的。)</p>

<p>对于之前那样的过拟合问题，显然是一个high variance问题，这类问题我们的学习曲线(Learning Curve)大概是这样的：
<img class="left" src="http://fieryfish.github.io/images/learning1.png" width="400" height="400" title="image" alt="From Novi 课件" /></p>

<p>相反地，一个high bias问题的Learning Curve：</p>

<p><img class="left" src="http://fieryfish.github.io/images/learning2.png" width="400" height="400" title="image" alt="From Novi 课件" /></p>

<p>对于分类问题，我们并不知道可以达到的最优结果(desired performance)是多少，
不过Learning Curve却是一个可以让你往这个方向去的直观的工具。
通过画Learning Curve，我们至少可以对现有的分类器有种‘感觉’，加之corss-validation，进而去避免high variance/high bias，
进而再通过优化自己的参数free parameter，去接近、达到desired performance。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[聊聊维数灾难(Curse of Dimensionality)]]></title>
    <link href="http://fieryfish.github.io/blog/2014/06/29/curse-dim/"/>
    <updated>2014-06-29T14:17:00+08:00</updated>
    <id>http://fieryfish.github.io/blog/2014/06/29/curse-dim</id>
    <content type="html"><![CDATA[<p>本文原文摘自<a href="http://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/">这里</a>,作部分修改。</p>

<p>这篇文章，聊聊很普遍的一个机器学习现象Curse of Dimensionality。首先，维度怎么会是一种‘灾难’呢？通过下面这个
非常直观的例子，我们来看看。
现在有这么一个分类任务，就是要区分10只‘狗’or‘猫’，给定的特征(feature)是基于颜色的（红、绿、蓝）。现在呢，我们考虑第一个
feature——<strong>红色</strong>。</p>

<p><img class="left" src="http://fieryfish.github.io/images/curse1.png" width="350" height="350" title="image" alt="1维" /></p>

<p>感觉不是太好？不能线性可分？那就再考虑一种feature——<strong>绿色</strong>！现在我们有2维feature了哦。</p>

<p><img class="left" src="http://fieryfish.github.io/images/curse2.png" width="350" height="350" title="image" alt="2维" /></p>

<p>感觉还是不是太好？还是不能线性可分？那就再再考虑一种feature——<strong>蓝色</strong>！现在我们有3维feature了哦~</p>

<p><img class="left" src="http://fieryfish.github.io/images/curse3.png" width="350" height="350" title="image" alt="3维" /></p>

<p>哇塞，现在可以找到一个平面去分离小猫小狗了！</p>

<p><img class="left" src="http://fieryfish.github.io/images/curse3yes.png" width="350" height="350" title="image" alt="3维--线性可分" /></p>

<p>这里要告诉大家一个事实，<strong>当维度越来越高的时候，那么线性可分的概率会越来越大，而且当其维度高到一定时候，线性可分的概率会到1</strong>。(源自Cover theorem)。
插播一下，我上面说的这个事实也是kernel trick的基础，所以本文跟kernel method有很大关系，他们的目的很简单，就是处理线性不可分数据，而处理的方法本质一样，而细节略有不同。
比如，来说RBF network可以使用Guassian function作为RBF function去处理线性不可分数据，SVM可能会选择kernel trick直接在高维度处理数据等等。
kernel method是机器学习很重要的一块，并不是说一定只能使用在SVM。我经常会觉得ML有时候更像是拼积木的游戏，
你想搭建一个城堡（SVM处理线性不可分数据），那你就会看看哪个积木（kernel trick）更适用，然后就拿过来用，
而积木(kernel trick)并不是说从属于你这所城堡。</p>

<p>回到直播，那么这时候我们会说：越高维度越好喽！
很不幸，维度高的‘灾难’这是显现出来了。就我们这个例子来说，假设每个维度有5个单位间隔（unit intervals），
开个玩笑的说：不太红，有点红，红，特别红，极度红。-_-! 那么10个instances的情况下，每个单位间隔有2个instance喽。
同样的问题升到2维，还是10个instances，但我们这时有5 x 5 = 25个单位间隔（unit squares）。
平均每个单位间隔这时只有 10/25 = 0.4个instance。 再升到3维就只有0.08了。
那这里的变化量就是我们的密度(Density), 也就是密度变得越来越小了，越来越稀疏(sparse)了。</p>

<p>下面这个图从另一个角度解释了维度高的‘灾难’。如果，分类器的feature的范围是0到1的连续情况，1维时候，
涵盖20%的feature只需要从全体（population）选20%个训练数据就可以了。但是如果升到2维，
我们确需要从全体选出45%的数据才能满足涵盖20%feature(0.45x0.45=0.2)。3维去要0.58(0.58^3=0.2)。
看来，相同的涵盖率，在维度增长时候，我们需要的训练数据是指数增加的。细细想想，也是很直观的，
更多的feature当然需要更多的训练数据喽，我在<a href="http://bboxers.com/blog/2014/06/16/probabilistic-models/">概率模型probabilistic Models (1)</a>
也聊过关于训练数据多少的问题。</p>

<p><img class="left" src="http://fieryfish.github.io/images/curse4a.png" width="600" height="600" title="image" alt="1-&gt;3维" /></p>

<p>下面一节我还会继续这个话题，先休息一下~不过是另外一个角度，主要是说learning curve。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[俯瞰Machine Learning]]></title>
    <link href="http://fieryfish.github.io/blog/2014/06/24/models/"/>
    <updated>2014-06-24T12:01:00+08:00</updated>
    <id>http://fieryfish.github.io/blog/2014/06/24/models</id>
    <content type="html"><![CDATA[<p>这篇的内容主要是摘自<a href="http://book.douban.com/subject/11453073/">Machine Learning</a>
这本书第一章节，我觉得蛮有收获的，希望可以提供一个不一样的角度。
另外，这本书真的不错，是我导师推荐的，最重要的是我们Sussex大学图书馆竟然有！我会告诉大家我们图书馆连一本介绍Ruby的书籍都没有么。。可能是因为这本书是Cambridge出的，作为英国同乡总要给些面子吧，就引进来了。</p>

<p>既然是‘俯瞰’，那肯定不是某些特定的技术。首先，问大家这样一个问题”Given a real world problem, how would you
reduce it to a ml problem.(一个实际问题如何转化成一个ML问题？)”
<a href="http://www.reddit.com/r/MachineLearning/comments/1wmayh/ml_job_interview_questions/">引自reddit</a>。
这样的问题好像很没有头绪，但是别慌。书里给出了一个蛮不错的答案：其实大多数机器学习问题都着重干的3件事是关于Task, Model, Feature的。
具体来说，实际的问题到底是要处理哪个Task：分类(classfication)? 回归(regression)? 聚类(clustering)?
而不同的问题也要根据其场景去选择不同的model（稍后详细描述）。
在真正使用模型的时候，更重要的可能是feature的选取、生成。例如：在SVM中的kernel trick就是一种关于feature的操作，亦或者
pre-processing。通常来讲，我们大多数情况下不能直接获取到适用于model的数据，自然要对feature进行一些处理喽。</p>

<p>这里我重点想聊一聊Model。在作者看来，Model有三大类型：Logical model, Probabilistic model, Geometry model.
大家可以试着回顾一下3种model里面包含的算法。这里我分别举例一下他们典型的代表: Decision Tree, Naive Bayes, SVM。
这样分类有什么好处呢就是各个类别有其特点。比如 Logical model比较直观(主要是Tree的表现形式)，其很多思想源自computer science
(如<a href="http://en.wikipedia.org/wiki/Disjunctive_normal_form">DNF</a>,<a href="http://en.wikipedia.org/wiki/Conjunctive_normal_form">CNF</a>)。
Probabilistic model的思想则更多是源自数学喽(尤其是概率与统计)。Geometry model也是很直观的，几乎所有课件都会来个二维平面，
然后各种正例反例加个decision boundary去解释来解释去，当然也免不了最优化，解析几何的一些数学概念。</p>

<p>在处理实际问题时，不知道大家有没有在意过这样一个角度，这些模型其实还有个区别就是在于输入数据的类型，即<strong>离散值</strong>、<strong>连续值</strong>。
其对应的概念就是Grouping model, Grading model。举个例子：训练数据里面有两个正例为(5.0, 3.0), (1.3, 2.4)，两个个反例为(-5.0, -3.0), (-1.3, -2.4)。
对于Geometry model可能直接画个直线(decision boundary)，然后告诉你在直线的一侧，任何数据都是正例，另一侧都是反例(连续的感觉有木有)。
而对于Decision Tree,可能会问你这样的问题，对于新来的数据(x,y), x和y &gt; 0乎?(离散的感觉有木有) 要是大于0呢，就是正例，否则呢，就都是反例。
从<a href="http://book.douban.com/subject/11453073/">书里</a>摘两个图给大家，希望大家能有个俯瞰的感觉。</p>

<p>字段说明(geometry model, probabilistic model, logical model, grouping model, grading model, discrete value, real value, supervised, unsupervised, multi-class)</p>

<p><img class="left" src="http://fieryfish.github.io/images/model1.png" width="600" height="600" title="image" alt="总结" />
<img class="left" src="http://fieryfish.github.io/images/model2.png" width="600" height="600" title="image" alt="总结2" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[感知器(Perceptron)里的选择题]]></title>
    <link href="http://fieryfish.github.io/blog/2014/06/18/perceptron/"/>
    <updated>2014-06-18T19:17:00+08:00</updated>
    <id>http://fieryfish.github.io/blog/2014/06/18/perceptron</id>
    <content type="html"><![CDATA[<p>感知器是相当重要的，原因很简单，它是Network的基础，不论是ANN，SVM，他们都有着类似基于感知器的神经元网络结构。
这也是为什么我在学校修Neural Network这门课时，光Perceptron的作业就占了50%的分数。
算法很简单，看看图很容易理解。
所以我在主要想聊聊这里面一些其他蛮有意思的东西，
在机器学习很多时候，我们发现”选择”是一个很重要的东西，不管是理论的建立还是实现的优化，都要做出种种选择，
今天我们就来看看Perceptron里面的一些选择题。</p>

<p>首先，想问下感知器的损失函数（loss function）的形式什么？
在很多情况下，我们用到的损失函数形式都是这个样子的：(引用自<a href="http://www.sussex.ac.uk/sussexneuroscience/people/person/201607">Luc</a>课件)</p>

<p><script type="math/tex">E(\bar{w})=\frac{1}{2}\Sigma(t_{i}-y_{i})^2</script> 
(1)</p>

<p>其中，<script type="math/tex">y_{i}</script> 是感知器对于第i个实例(instance)的输出/预测(+1,-1)，$t_{i}$ 是第i个实例的原本的类别(+1,-1)。</p>

<p>为什么对于线性可分数据，普遍的感知器的loss function的选择却变成了这个样子？</p>

<p><script type="math/tex">E(\bar{w})=-\Sigma \bar{w} \cdot \bar{x_{i}} \cdot t_{i}</script>
（for all misclassified $\bar{x_{i}}$） (2)</p>

<p>其中w是权重，<script type="math/tex">x_{i}</script>是第i个实例(instance)的值，$t_{i}$是第i个实例的类别。</p>

<p><img class="left" src="http://fieryfish.github.io/images/perceptron.png" width="350" height="350" title="image" alt="perceptron" /></p>

<p>由这个图，我们可以看到，(2)式可以告诉我们更多误分类(misclassified)点的信息，
具体来说，就是误分类点与分界线(decision boundary)的远近跟loss function成正比，这样loss function越大，
说明误分类点离得越远，反之亦然。
这样看来，(2)式就显得更加合理，因为每一次更新，如果某个误分类点的误差太大，那么这次更新的时候就纠正的更多。</p>

<p>至于更新法则：</p>

<p><script type="math/tex">\bar{w}(t+1) = \bar{w}(t) + \eta \bar{x_{i}} \cdot t_{i}</script>
（for all misclassified $\bar{x_{i}}$）</p>

<p>(<a href="http://book.douban.com/subject/10590856/">统计学习方法</a>给出的形式)</p>

<p>等价于:</p>

<script type="math/tex; mode=display">\bar{w}(t+1) = \bar{w}(t) + \eta \bar{x_{i}} \cdot (t_{i}-y_{i})</script>

<p>$y_{i}$感知器对于第i个实例的输出。(<a href="http://book.douban.com/subject/1102235/">机器学习(Tom Mitchell)</a>给出的形式)</p>

<p>另外的一个问题，对于我们这个问题，我们应该用批量(batch)梯度下降还是随机(stochastic)梯度下降呢？</p>

<p>简单的答案是随机(stochastic)梯度下降。(<a href="http://www.quora.com/Machine-Learning/Whats-the-difference-between-gradient-descent-and-stochastic-gradient-descent">参考</a>)
不过前提是数据线性可分，随机(stochastic)梯度下降的缺点之一就是会导致不能收敛，即使十分接近于极小值。</p>

<p>这一次我们做了几个选择题，而大家也可以看到，
Perceptron的模型很简单，重点是要在适当的时刻选择一些适当的工具。
其实如果是现实的场景，面临的选择更多了，比如梯度下降的终止条件应该怎么选择？步长呢？初始值呢？
如果数据线性不可分，我们的算法又要怎么选择？stochastic -&gt; batch
<!--这里，不得不说，ML是一个选择是世界，一个算法的好坏，往往不在于算法本身，而在于根据数据进行的选择，-->
<!--比如SVM，如果都是用默认参数，起初的效果一般都不是很理想，但是可以慢慢调节参数以后，大都会提高很明显。说了这么多，就是强调一下：**选择**很重要。--></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[概率模型probabilistic models (1)]]></title>
    <link href="http://fieryfish.github.io/blog/2014/06/16/probabilistic-models/"/>
    <updated>2014-06-16T15:34:00+08:00</updated>
    <id>http://fieryfish.github.io/blog/2014/06/16/probabilistic-models</id>
    <content type="html"><![CDATA[<p>之前说到我在公司是做Ruby on rails程序员，后来转到数据这块（小公司+好老板的好处就是可以无损的转去做自己喜欢的项目），
面临的第一个项目就是做一个分类器，而我第一个采用的第一个模型就是概率模型(probabilistic models)，
具体分类器是<a href="http://zh.wikipedia.org/zh/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8">朴素贝叶斯分类器</a>。
效果在当时的我们看来，可以总结为三个字：碉堡了。我当时看到结果真的蛮震惊的，从前上课时候一扫而过的贝叶斯公式竟然有如此威力！</p>

<p>首先，如果对于朴素贝叶斯或者贝叶斯公式还不打了解的同学，我的建议是：拿出一张纸和一支笔，去<a href="http://www.ruanyifeng.com/blog/2013/12/naive_bayes_classifier.html">阮一峰的blog</a>
搜索、学习贝叶斯相关内容。（阮一峰的blog很有文采，强烈推荐之）。
在我看到‘朴素贝叶斯(Naive Bayes)’这几个字以后，对我来讲比较敏感的字眼其实是‘朴素(Naive)’两个字，
贝叶斯就贝叶斯，怎么还naive呢？
其实，他表示的是一个简化的假设（assumption），即假设数据的特征(feature)/属性/字段是条件独立的(conditional independent)，why？
举个例子（引用我的导师<a href="http://www.sussex.ac.uk/profiles/335583/publications">Novi</a>）：假设我们要训练样例是20个features组成的，每个feature都是取值二元的（即可以取0或者1，no或者yes），
样例的类别（class label）也是二元的，</p>

<script type="math/tex; mode=display">p(X_{1},X_{2}..X_{20}|Y)</script>

<p>那么，概率的估计（probability estimates）有多少种可能呢？也就是假设空间(hypothesis space)的大小是多少？
我的答案：
$2^{21} -1=2097151个$
（每个Feature有两种，class label有两种，减1是因为概率之和必须为1，减去一个自由度）</p>

<p>所以这就导致了我们至少要学习2097151个样例才可以保证贝叶斯公式可以用，是不是很恐怖。
这也就是为什么我们需要一个条件独立假设，即</p>

<script type="math/tex; mode=display">P(X_{1},X_{2}..X_{20}|Y) := P(X_{1}|Y)\cdot P(X_{2}|Y)...P(X_{20}|Y)</script>

<p>这时候，概率的估计（probability estimates）有多少种可能呢？
我的答案是41个，
（我的解释：对于每一项P(X|Y)来说，给定了Y值，X的自由度是1，因为其概率和是1，而Y有两种可能取值，所以一共2*20=40,
再加上P(Y)还有一个自由度，一共就是41）
显然，naive Bayes小了很多，对于训练的要求减小了。
那再引出一个问题，什么是‘不朴素(non-naive)’的分类器呢？</p>

<p>回归到我当时的任务，简单场景就是：每个商铺/网店都有一些描述信息，我们想根据字段的信息（比如‘地址address’）把他们分类到相关城市city去。
做这个任务的模型很简单，首先将地址分词，得到word1,word2,word3…,得到相应公式(以分成两个词为例)：</p>

<script type="math/tex; mode=display">P(Y_{city}|X_{word1},X_{word2})=\frac{P(X_{word1}|Y_{city})\cdot P(X_{word2}|Y_{city})\cdot (p_{Y_{city}})}{P(X_{word1})\cdot P(X_{word2})}</script>

<p>由于分类时候，分子都是是一样的，可以不考虑。再假设
$P(Y_{city})$
是均匀分布(uniform distribution)，又可以
忽略这个值（但不总是满足uniform distribution, 先验知识有时候是很重要的），那么最终的分类过程相当于</p>

<script type="math/tex; mode=display">P^{\ast}(Y_{city}|X_{word1},X_{word2})=\operatorname{argmax}_Y (P(X_{word1}|Y_{city})\cdot P(X_{word2}|Y_{city}))</script>

<p>在实际应用时候，naive Bayes有个特别的优势：有些地址是不太好判别，而这一类的地址，在计算后验概率的时候，
概率较大的几组概率都很相近，导致很难‘确信’地把这些样例分类到相关城市。比如: (长春和北京都有朝阳区哦~)</p>

<script type="math/tex; mode=display">P(Y_{北京}|X_{朝阳区})=0.3 , ~~
P(Y_{长春}|X_{朝阳区})=0.33</script>

<p>那么通过naive Bayes可以加一些简单的判断去提取这些很容易出错的实例，是不是很有用呢。^-^
另外,先验知识(prior knowledge)也可以被当做因素考虑进来，例如：根据上面的概率
<script type="math/tex">P(Y_{长春}|X_{朝阳区}) > P(Y_{北京}|X_{朝阳区})</script>
因此，这个实例应该被分到<strong>长春</strong>。</p>

<p>但是考虑先验知识
<script type="math/tex">P(Y_{北京})=0.5, ~~ P(Y_{长春})=0.3</script></p>

<p>那么
<script type="math/tex">% &lt;![CDATA[
P(Y_{长春}|X_{朝阳区})\cdot P(Y_{长春}) < P(Y_{北京}|X_{朝阳区})\cdot P(Y_{北京}) %]]&gt;</script>
因此，这个实例应该被分到<strong>北京</strong>。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hello Machine Learning]]></title>
    <link href="http://fieryfish.github.io/blog/2014/06/15/hello-machine-learning/"/>
    <updated>2014-06-15T18:16:00+08:00</updated>
    <id>http://fieryfish.github.io/blog/2014/06/15/hello-machine-learning</id>
    <content type="html"><![CDATA[<p>‘hello world’似乎像是技术的入场礼，不同的人总在开始的时候用尽一些办法，就是为了看到’hello XXX’这几个字母
闪现在屏幕的那一刹那。现在我也盗用这个仪式，开始聊聊我对于Machine Learning(ML)的理解。
我觉得学东西直观的感觉(intuition)和基于问题的学习很重要啊，尤其是抽象的东西，比如: ML -_-!
所以我会主要通过这样方式谈谈我理解。同样，一些拼写标点错误也请大家见谅，从小考试都是丢三落四，所以老师
都给我起了个外号”准优等”。文笔我也不会很严谨，毕竟哀家才是研究僧，说话不会像公知一样对大家负责。
该啰嗦的就啰嗦到这里了~</p>

<p>总有一些事情是你一看上去就决定要终身相伴的，这可能就是我一看到machine learning的感觉吧。
还记得一年半前，我还是一个ruby on rails程序员，也是个应届生，在一家创业公司做码农。所以对于一切都是充满好奇，却也是很傻很天真。
总爱问别人很幼稚的问题，例如：
你为啥学这个啊？你觉得我学啥对我有帮助啊？等等这些。。
直到我发现一本书，<a href="http://book.douban.com/subject/3288908/">集体智慧编程(Programming Collective Intelligence)</a>，我觉得我的下一步应该是学这样子的知识！
看起来很有用，而且也很高大上的样子。而且，恰好当时公司一个技术大牛也开始研究这个领域。我就抱大腿似的
准备跟他一起搞。后来，经过一阵小小研究后，我们竟然真的做成了一些项目，那会真是兴奋地不行不行的。后面会具体介绍。</p>

<p>其实我相信对于初学者，每个人都会觉得’我擦，这东西太难了吧！怎么需要学那么多东西。而且，它需要说得过去的数学功底。’
是的，这是事实，毋庸置疑，要不岂不是谁都可以研究它了么。但是说白了，机器学习算法(algorithm)或者模型(model)本质来说就是一个
映射(mapping)而已，你所要的不就是将你的输入(input)得到个输出(output)么，而且那些复杂的算法往往开始的起因都是很简单的，
很多复杂的地方往往都是后期人们缝缝补补、增增减减的结果。这点，吴军老师在<a href="http://book.douban.com/subject/10750155/">数学之美</a>早有论述，我也对此坚信不疑，对了，这是一本好书。
但是，我在强调一下，但是，一些基础的先验知识很重要。已<a href="http://book.douban.com/subject/1102235/">机器学习(Tom Mitchell)</a>为例，概念学习那张我至少看了4遍，
还是没懂它在讲啥，什么归纳偏置(inductive bias)，假设空间，目标函数都不知道整这些概念干嘛使。
所以嘞，我的建议就是，弄了半天还不会的就搁一边，他会再出现的，到时候你肯定会如梦方醒的，因为慢慢积累这些概念以后，
会发现他们很多都是相通的，去弄懂某个孤立点的难度肯定比掌握点和点联系、区别困难很多。</p>

<p>最后我想说说我认为的学习机器学习的技巧吧。1 会<strong>读英文</strong>。不然，就只能看<a href="http://book.douban.com/subject/1102235/">机器学习(Tom Mitchell)</a>了吧。
可能也有别的选择，但我去年去清华蹭课他们用的就是这个教材，要是不靠老师讲解而是自学，蛮难的。
有些人很容易有个误会，就是会英文这门槛太高了，其实啊，专业词语就那么多，而且读英文的难度远远小于说和写，
开始慢慢来，之后就会很舒服了。2 <strong>直观理解</strong>。很多公式用一个图就解释的明明白白的。3 <strong>结合实践</strong>。看了不一定会明白，
明白了不一定理解，理解了不一定会做，做的话可以去(Kaggle.com)练练手。4 <strong>讲给别人</strong>。
我曾经问过我导师，我什么时候才能像你一样对于ML侃侃而谈，他笑着对我说:”等你可以把他讲给别人，让别人也理解，对于
他们的问题你可以解答。”这，就是为什么我开始写这个博客吧，而且，这是捷径。
5 <strong>基础知识</strong>,尽管数学面积很大，但至少梯度下降，贝叶斯这些必备知识要完全掌握。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Get Start]]></title>
    <link href="http://fieryfish.github.io/blog/2013/03/17/kai-shi-bloglu-cheng/"/>
    <updated>2013-03-17T18:44:00+08:00</updated>
    <id>http://fieryfish.github.io/blog/2013/03/17/kai-shi-bloglu-cheng</id>
    <content type="html"><![CDATA[<p>一直说要搞个blog写写东西，结果拖拖拉拉一直到现在，很早之前读<a href="http://book.douban.com/subject/6709809/">暗时间</a>的时候就想搭建一个blog去总结一下知识，如今终于开始这个旅程了。我分享的东西也主要是自己的总结，如果偶尔有些话能帮助到各位看官我也就心满意足了。</p>

<p>我相信只有经过思考的知识才是有价值的，所以我的文字肯定都是自己经过思考去码的，大家如果有什么想法意见也希望思考后再传达给我。最终目标希望大家把这里视作一个平台，能让大家在这里汲取、思考。</p>

<p>为什么选择<strong>bboxers.com</strong>的域名？ 因为我喜欢节奏，尤其是bbox，我的偶像是<strong>alem</strong>。peace</p>

]]></content>
  </entry>
  
</feed>
